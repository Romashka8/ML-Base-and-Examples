{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b32954c-2196-4c8d-8834-d2873adff282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 16:42:53.365334: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-01 16:42:53.369383: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-01 16:42:53.380781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733060573.399799   17907 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733060573.405476   17907 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 16:42:53.425703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1389f-cde9-4842-be43-af317124c538",
   "metadata": {},
   "source": [
    "✅Write down more dificult architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f5c36b-5871-4915-b91a-63eb42e51e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    activation_functions = {\n",
    "        'softmax': lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True),\n",
    "        'tanh': np.tanh\n",
    "    }\n",
    "    \n",
    "    def __init__(self, input_size: tuple[int, int], activation: str='tanh', alpha_const: float=0.02, c_const: float=0.01):\n",
    "        self.weights = alpha_const * np.random.random(input_size) - c_const\n",
    "        self.activation = self.activation_functions[activation]\n",
    "        self.derivative = lambda x: 1 - np.tanh(x) ** 2 if activation == 'tanh' else None\n",
    "        self.output = None\n",
    "\n",
    "    def activate(self, inputs: np.array):\n",
    "        z = np.dot(inputs, self.weights)\n",
    "        self.output = self.activation(z)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cac4a7a-c16f-4c13-a58f-f3a0214394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, neurons: list, batch_size: int=100, learning_rate: float=0.1):\n",
    "        self.neurons = neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x: np.array) -> np.array:\n",
    "        for neuron in self.neurons:\n",
    "            x = neuron.activate(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, output: np.array, y: np.array, batch_start: int, batch_end: int):\n",
    "        delta = None\n",
    "        \n",
    "        for i in range(len(self.neurons) - 1, 0, -1):\n",
    "            neuron = self.neurons[i]\n",
    "            if i == len(self.neurons) - 1:\n",
    "                delta = (y[batch_start:batch_end] - output) / (self.batch_size * output.shape[0])\n",
    "            else:\n",
    "                delta = delta.dot(neuron.weights) * neuron.derivative(neuron.output)\n",
    "            neuron.weights += self.learning_rate * self.neurons[i - 1].output.T.dot(delta)\n",
    "    \n",
    "    def train(self, x_train: np.array, y_train: np.array, x_test: np.array, y_test: np.array, epochs: int=10, verbose: Optional[int]=10):\n",
    "        for epoch in range(epochs):\n",
    "            correct_cnt = 0\n",
    "            for i in range(int(len(x_train) / batch_size)):\n",
    "                batch_start, batch_end = ((i * batch_size), ((i + 1) * self.batch_size))\n",
    "                input = x_train[batch_start:batch_end]\n",
    "                output = self.forward(input)\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    correct_cnt += int(np.argmax(output[k:k+1]) == np.argmax(y_train[batch_start+k:batch_end+k+1]))\n",
    "\n",
    "                self.backward(output, y_train, batch_start, batch_end)\n",
    "\n",
    "            test_correct_cnt = 0\n",
    "\n",
    "            for i in range(len(x_test)):\n",
    "                input = x_test[i:i+1]\n",
    "                output = self.forward(input)\n",
    "\n",
    "                test_correct_cnt += int(np.argmax(output) == np.argmax(y_test[i:i+1]))\n",
    "\n",
    "            if verbose and epoch % verbose == 0:\n",
    "                sys.stdout.write('\\n' + \\\n",
    "                    'I:' + str(epoch) + \\\n",
    "                    ' Test-Acc:' + str(test_correct_cnt/float(len(test_images)))+\\\n",
    "                    ' Train-Acc:' + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6012333-924f-4cc6-94e8-5d3890a8b37d",
   "metadata": {},
   "source": [
    "✅Load and scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e999bdb-01f6-4a91-b989-9eb0d23e2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(y_data: np.array) -> np.array:\n",
    "    y_coded = np.zeros((len(y_data), 10))\n",
    "    for i, l in enumerate(y_data):\n",
    "        y_coded[i][l] = 1\n",
    "    return y_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19492405-57fb-40fe-bd35-85a41ed7d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = x_train[:1000].reshape(1000, 28 * 28) / 255, y_train[:1000]\n",
    "test_images = x_test.reshape(len(x_test), 28 * 28) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9266269f-70d1-46ac-b8b0-49f62df22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = one_hot_encoder(labels)\n",
    "test_labels = one_hot_encoder(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fead6-95e7-4e76-8d61-fd8c21779605",
   "metadata": {},
   "source": [
    "✅ Design and train our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d767c6ce-792f-4ae9-98fa-079bb2702239",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, epochs, hidden_size = (2, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ae27f0-402c-48c4-8ae6-db8b5e4e360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron1 = Neuron((pixels_per_image, hidden_size))\n",
    "neuron2 = Neuron((hidden_size, num_labels), activation='softmax', alpha_const=0.2, c_const=0.1)\n",
    "\n",
    "network = Network([neuron1, neuron2], batch_size=batch_size, learning_rate=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c990f49-020a-48ad-9bf1-845195a1d131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Acc:0.0986 Train-Acc:0.087\n",
      "I:10 Test-Acc:0.1354 Train-Acc:0.145\n",
      "I:20 Test-Acc:0.1775 Train-Acc:0.195\n",
      "I:30 Test-Acc:0.2332 Train-Acc:0.258\n",
      "I:40 Test-Acc:0.2939 Train-Acc:0.331\n",
      "I:50 Test-Acc:0.3488 Train-Acc:0.382\n",
      "I:60 Test-Acc:0.393 Train-Acc:0.451\n",
      "I:70 Test-Acc:0.4363 Train-Acc:0.495\n",
      "I:80 Test-Acc:0.4757 Train-Acc:0.539\n",
      "I:90 Test-Acc:0.5075 Train-Acc:0.57\n",
      "I:100 Test-Acc:0.5343 Train-Acc:0.596\n",
      "I:110 Test-Acc:0.5523 Train-Acc:0.618\n",
      "I:120 Test-Acc:0.5672 Train-Acc:0.636\n",
      "I:130 Test-Acc:0.5809 Train-Acc:0.656\n",
      "I:140 Test-Acc:0.5915 Train-Acc:0.662\n",
      "I:150 Test-Acc:0.6009 Train-Acc:0.673\n",
      "I:160 Test-Acc:0.6101 Train-Acc:0.677\n",
      "I:170 Test-Acc:0.617 Train-Acc:0.68\n",
      "I:180 Test-Acc:0.6222 Train-Acc:0.681\n",
      "I:190 Test-Acc:0.6275 Train-Acc:0.677\n",
      "I:200 Test-Acc:0.6301 Train-Acc:0.683\n",
      "I:210 Test-Acc:0.6345 Train-Acc:0.683\n",
      "I:220 Test-Acc:0.6371 Train-Acc:0.684\n",
      "I:230 Test-Acc:0.6398 Train-Acc:0.686\n",
      "I:240 Test-Acc:0.6424 Train-Acc:0.684\n",
      "I:250 Test-Acc:0.6441 Train-Acc:0.687\n",
      "I:260 Test-Acc:0.6468 Train-Acc:0.69\n",
      "I:270 Test-Acc:0.6485 Train-Acc:0.69\n",
      "I:280 Test-Acc:0.6496 Train-Acc:0.689\n",
      "I:290 Test-Acc:0.6511 Train-Acc:0.693CPU times: user 11min 37s, sys: 7min 28s, total: 19min 6s\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "network.train(images, labels, test_images, test_labels, epochs=epochs, verbose=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
