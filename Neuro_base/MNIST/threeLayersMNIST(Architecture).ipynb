{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b32954c-2196-4c8d-8834-d2873adff282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 13:36:10.916101: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-03 13:36:10.992703: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-03 13:36:11.052016: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733222171.115853    5642 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733222171.142975    5642 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 13:36:11.302373: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from typing import Optional\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d1389f-cde9-4842-be43-af317124c538",
   "metadata": {},
   "source": [
    "✅Write down more dificult architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f5c36b-5871-4915-b91a-63eb42e51e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    activation_functions = {\n",
    "        'softmax': lambda x: np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True),\n",
    "        'tanh': np.tanh\n",
    "    }\n",
    "    \n",
    "    def __init__(self, input_size: tuple[int, int], activation: str='tanh', alpha_const: float=0.02, c_const: float=0.01,\n",
    "                 dropout: bool=False):\n",
    "        self.weights = alpha_const * np.random.random(input_size) - c_const\n",
    "        self.activation = self.activation_functions[activation]\n",
    "        self.derivative = lambda x: 1 - np.tanh(x) ** 2 if activation == 'tanh' else None\n",
    "        self.dropout = dropout\n",
    "        self.output = None\n",
    "\n",
    "    def activate(self, inputs: np.array):\n",
    "        z = np.dot(inputs, self.weights)\n",
    "        self.output = self.activation(z)\n",
    "        if self.dropout:\n",
    "            dropout_mask = np.random.randint(2, size=self.output.shape)\n",
    "            self.output *= dropout_mask * 2\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cac4a7a-c16f-4c13-a58f-f3a0214394e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, neurons: list, batch_size: int=100, learning_rate: float=0.1):\n",
    "        self.neurons = neurons\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x: np.array) -> np.array:\n",
    "        for neuron in self.neurons:\n",
    "            x = neuron.activate(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, output: np.array, y: np.array, batch_start: int, batch_end: int):\n",
    "        delta = None\n",
    "        \n",
    "        for i in range(len(self.neurons) - 1, 0, -1):\n",
    "            neuron = self.neurons[i]\n",
    "            if i == len(self.neurons) - 1:\n",
    "                delta = (y[batch_start:batch_end] - output) / (self.batch_size * output.shape[0])\n",
    "            else:\n",
    "                delta = delta.dot(neuron.weights) * neuron.derivative(neuron.output)\n",
    "            neuron.weights += self.learning_rate * self.neurons[i - 1].output.T.dot(delta)\n",
    "    \n",
    "    def train(self, x_train: np.array, y_train: np.array, x_test: np.array, y_test: np.array, epochs: int=10, verbose: Optional[int]=10):\n",
    "        for epoch in range(epochs):\n",
    "            error, correct_cnt = (0.0,0)\n",
    "            for i in range(int(len(x_train) / batch_size)):\n",
    "                batch_start, batch_end = ((i * batch_size), ((i + 1) * self.batch_size))\n",
    "                input = x_train[batch_start:batch_end]\n",
    "                output = self.forward(input)\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    error += np.sum((y_train[k:k+1] - output) ** 2)\n",
    "                    correct_cnt += int(np.argmax(output[k:k+1]) == np.argmax(y_train[batch_start+k:batch_end+k+1]))\n",
    "\n",
    "                self.backward(output, y_train, batch_start, batch_end)\n",
    "\n",
    "            test_correct_cnt = 0\n",
    "            test_error = 0.0\n",
    "            \n",
    "            for i in range(len(x_test)):\n",
    "                input = x_test[i:i+1]\n",
    "                output = self.forward(input)\n",
    "\n",
    "                test_correct_cnt += int(np.argmax(output) == np.argmax(y_test[i:i+1]))\n",
    "                test_error += np.sum((y_test[i:i+1] - output) ** 2)\n",
    "            \n",
    "            if verbose and epoch % verbose == 0:\n",
    "                sys.stdout.write(\"\\n\" + \\\n",
    "                        \"I:\" + str(epoch) + \\\n",
    "                        \" Test-Err:\" + str(test_error/ float(len(test_images)))[0:5] +\\\n",
    "                        \" Test-Acc:\" + str(test_correct_cnt/ float(len(test_images)))+\\\n",
    "                        \" Train-Err:\" + str(error/ float(len(images)))[0:5] +\\\n",
    "                        \" Train-Acc:\" + str(correct_cnt/ float(len(images))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6012333-924f-4cc6-94e8-5d3890a8b37d",
   "metadata": {},
   "source": [
    "✅Load and scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e999bdb-01f6-4a91-b989-9eb0d23e2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(y_data: np.array) -> np.array:\n",
    "    y_coded = np.zeros((len(y_data), 10))\n",
    "    for i, l in enumerate(y_data):\n",
    "        y_coded[i][l] = 1\n",
    "    return y_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19492405-57fb-40fe-bd35-85a41ed7d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "images, labels = x_train[:1000].reshape(1000, 28 * 28) / 255, y_train[:1000]\n",
    "test_images = x_test.reshape(len(x_test), 28 * 28) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9266269f-70d1-46ac-b8b0-49f62df22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = one_hot_encoder(labels)\n",
    "test_labels = one_hot_encoder(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fead6-95e7-4e76-8d61-fd8c21779605",
   "metadata": {},
   "source": [
    "✅ Design and train our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d767c6ce-792f-4ae9-98fa-079bb2702239",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, epochs, hidden_size = (2, 500, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ae27f0-402c-48c4-8ae6-db8b5e4e360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron1 = Neuron((pixels_per_image, hidden_size), dropout=True)\n",
    "neuron2 = Neuron((hidden_size, num_labels), activation='softmax', alpha_const=0.2, c_const=0.1)\n",
    "\n",
    "network = Network([neuron1, neuron2], batch_size=batch_size, learning_rate=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48051c46-72e7-4667-b80f-daeb26d360c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.900 Test-Acc:0.0827 Train-Err:90.00 Train-Acc:0.067\n",
      "I:10 Test-Err:0.899 Test-Acc:0.1142 Train-Err:90.00 Train-Acc:0.109\n",
      "I:20 Test-Err:0.897 Test-Acc:0.1521 Train-Err:90.00 Train-Acc:0.146\n",
      "I:30 Test-Err:0.896 Test-Acc:0.1935 Train-Err:90.00 Train-Acc:0.197\n",
      "I:40 Test-Err:0.894 Test-Acc:0.2426 Train-Err:90.00 Train-Acc:0.263\n",
      "I:50 Test-Err:0.893 Test-Acc:0.2791 Train-Err:90.00 Train-Acc:0.298\n",
      "I:60 Test-Err:0.892 Test-Acc:0.3202 Train-Err:90.00 Train-Acc:0.349\n",
      "I:70 Test-Err:0.890 Test-Acc:0.3584 Train-Err:90.00 Train-Acc:0.377\n",
      "I:80 Test-Err:0.889 Test-Acc:0.3865 Train-Err:90.00 Train-Acc:0.425\n",
      "I:90 Test-Err:0.887 Test-Acc:0.4057 Train-Err:90.01 Train-Acc:0.424\n",
      "I:100 Test-Err:0.886 Test-Acc:0.4251 Train-Err:90.01 Train-Acc:0.473\n",
      "I:110 Test-Err:0.884 Test-Acc:0.4517 Train-Err:90.02 Train-Acc:0.486\n",
      "I:120 Test-Err:0.883 Test-Acc:0.4592 Train-Err:90.02 Train-Acc:0.502\n",
      "I:130 Test-Err:0.882 Test-Acc:0.4765 Train-Err:90.02 Train-Acc:0.507\n",
      "I:140 Test-Err:0.880 Test-Acc:0.489 Train-Err:90.03 Train-Acc:0.516\n",
      "I:150 Test-Err:0.879 Test-Acc:0.499 Train-Err:90.03 Train-Acc:0.529\n",
      "I:160 Test-Err:0.877 Test-Acc:0.5024 Train-Err:90.04 Train-Acc:0.542\n",
      "I:170 Test-Err:0.876 Test-Acc:0.5069 Train-Err:90.05 Train-Acc:0.569\n",
      "I:180 Test-Err:0.875 Test-Acc:0.5224 Train-Err:90.06 Train-Acc:0.576\n",
      "I:190 Test-Err:0.873 Test-Acc:0.5257 Train-Err:90.07 Train-Acc:0.57\n",
      "I:200 Test-Err:0.872 Test-Acc:0.5294 Train-Err:90.07 Train-Acc:0.59\n",
      "I:210 Test-Err:0.870 Test-Acc:0.5284 Train-Err:90.08 Train-Acc:0.575\n",
      "I:220 Test-Err:0.869 Test-Acc:0.5435 Train-Err:90.09 Train-Acc:0.589\n",
      "I:230 Test-Err:0.868 Test-Acc:0.5454 Train-Err:90.10 Train-Acc:0.577\n",
      "I:240 Test-Err:0.866 Test-Acc:0.546 Train-Err:90.10 Train-Acc:0.595\n",
      "I:250 Test-Err:0.865 Test-Acc:0.5519 Train-Err:90.12 Train-Acc:0.605\n",
      "I:260 Test-Err:0.863 Test-Acc:0.558 Train-Err:90.13 Train-Acc:0.615\n",
      "I:270 Test-Err:0.862 Test-Acc:0.5531 Train-Err:90.14 Train-Acc:0.592\n",
      "I:280 Test-Err:0.861 Test-Acc:0.5555 Train-Err:90.15 Train-Acc:0.609\n",
      "I:290 Test-Err:0.859 Test-Acc:0.5579 Train-Err:90.16 Train-Acc:0.596\n",
      "I:300 Test-Err:0.858 Test-Acc:0.5692 Train-Err:90.18 Train-Acc:0.609\n",
      "I:310 Test-Err:0.856 Test-Acc:0.5663 Train-Err:90.19 Train-Acc:0.61\n",
      "I:320 Test-Err:0.855 Test-Acc:0.5641 Train-Err:90.20 Train-Acc:0.616\n",
      "I:330 Test-Err:0.853 Test-Acc:0.5759 Train-Err:90.21 Train-Acc:0.622\n",
      "I:340 Test-Err:0.852 Test-Acc:0.5715 Train-Err:90.23 Train-Acc:0.62\n",
      "I:350 Test-Err:0.851 Test-Acc:0.5771 Train-Err:90.24 Train-Acc:0.619\n",
      "I:360 Test-Err:0.849 Test-Acc:0.5808 Train-Err:90.26 Train-Acc:0.615\n",
      "I:370 Test-Err:0.848 Test-Acc:0.5735 Train-Err:90.27 Train-Acc:0.624\n",
      "I:380 Test-Err:0.846 Test-Acc:0.5795 Train-Err:90.30 Train-Acc:0.648\n",
      "I:390 Test-Err:0.845 Test-Acc:0.5716 Train-Err:90.31 Train-Acc:0.626\n",
      "I:400 Test-Err:0.843 Test-Acc:0.581 Train-Err:90.32 Train-Acc:0.626\n",
      "I:410 Test-Err:0.842 Test-Acc:0.5788 Train-Err:90.34 Train-Acc:0.629\n",
      "I:420 Test-Err:0.841 Test-Acc:0.5774 Train-Err:90.35 Train-Acc:0.631\n",
      "I:430 Test-Err:0.839 Test-Acc:0.5778 Train-Err:90.36 Train-Acc:0.623\n",
      "I:440 Test-Err:0.837 Test-Acc:0.5848 Train-Err:90.39 Train-Acc:0.636\n",
      "I:450 Test-Err:0.837 Test-Acc:0.5848 Train-Err:90.41 Train-Acc:0.635\n",
      "I:460 Test-Err:0.835 Test-Acc:0.5823 Train-Err:90.43 Train-Acc:0.64\n",
      "I:470 Test-Err:0.834 Test-Acc:0.5834 Train-Err:90.46 Train-Acc:0.637\n",
      "I:480 Test-Err:0.832 Test-Acc:0.5873 Train-Err:90.47 Train-Acc:0.635\n",
      "I:490 Test-Err:0.831 Test-Acc:0.584 Train-Err:90.51 Train-Acc:0.617CPU times: user 31min 40s, sys: 20min 54s, total: 52min 34s\n",
      "Wall time: 13min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "network.train(images, labels, test_images, test_labels, epochs=epochs, verbose=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
